"""
Yeni Veri √úretim Scripti
Model kullanarak ger√ßek√ßi veri √ºretir ve Firebase'e kaydeder
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import sys
from model_egit import load_model, predict_anomaly, calculate_risk_score
from config import (
    NUM_TRANSFORMERS,
    TRANSFORMER_LOCATIONS,
    SENSOR_RANGES,
    DATA_GENERATION
)

def generate_realistic_data(transformer_id, category='normal', num_records=100):
    """
    Model kullanarak ger√ßek√ßi veri √ºretir.
    
    Args:
        transformer_id: Trafo ID
        category: 'normal', 'medium', 'high'
        num_records: √úretilecek kayƒ±t sayƒ±sƒ±
    """
    # Modeli y√ºkle
    try:
        model, scaler = load_model()
        print(f"‚úÖ Model y√ºklendi - Trafo {transformer_id}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Model y√ºklenemedi, varsayƒ±lan deƒüerler kullanƒ±lacak: {e}")
        model = None
        scaler = None
    
    data = []
    location = TRANSFORMER_LOCATIONS[transformer_id - 1]
    
    # Kategoriye g√∂re temel deƒüerler
    if category == 'normal':
        base_resistance = np.random.uniform(2.5, 4.0)
        base_leakage = np.random.uniform(1.0, 6.0)
        base_corrosion = np.random.uniform(5.0, 15.0)
    elif category == 'medium':
        base_resistance = np.random.uniform(5.0, 8.0)
        base_leakage = np.random.uniform(8.0, 15.0)
        base_corrosion = np.random.uniform(20.0, 40.0)
    else:  # high
        base_resistance = np.random.uniform(10.0, 20.0)
        base_leakage = np.random.uniform(20.0, 50.0)
        base_corrosion = np.random.uniform(50.0, 90.0)
    
    start_date = datetime.now() - timedelta(days=30)  # Son 30 g√ºn
    
    for i in range(num_records):
        timestamp = start_date + timedelta(hours=i * 6)  # Her 6 saatte bir
        
        # Normal dalgalanmalar
        resistance = base_resistance + np.random.normal(0, 0.3)
        leakage = base_leakage + np.random.normal(0, 1.5)
        potential = np.random.uniform(-2.0, 2.0)
        moisture = np.random.uniform(30.0, 50.0)
        temperature = np.random.uniform(15.0, 25.0)
        corrosion = base_corrosion + np.random.normal(0, 2.0)
        
        # Deƒüerleri sƒ±nƒ±rlar i√ßinde tut
        resistance = np.clip(resistance, 0.5, 25.0)
        leakage = np.clip(leakage, 0.0, 100.0)
        corrosion = np.clip(corrosion, 0.0, 100.0)
        
        sensor_data = {
            'timestamp': timestamp.isoformat(),
            'transformer_id': transformer_id,
            'toprak_direnci': round(resistance, 2),
            'kacak_akim': round(leakage, 2),
            'toprak_potansiyel': round(potential, 2),
            'toprak_nemi': round(moisture, 2),
            'toprak_sicakligi': round(temperature, 2),
            'korozyon_seviyesi': round(corrosion, 2),
            'latitude': location['latitude'],
            'longitude': location['longitude'],
            'name': location['name'],
            'region': location['region']
        }
        
        # Model ile analiz (varsa)
        if model and scaler:
            try:
                is_anomaly, anomaly_score = predict_anomaly(model, scaler, sensor_data)
                risk_score = calculate_risk_score(anomaly_score, sensor_data)
                
                # Kategoriye g√∂re risk skorunu ayarla
                if category == 'normal':
                    risk_score = max(15, min(35, risk_score * 0.3))
                elif category == 'medium':
                    risk_score = max(45, min(65, risk_score * 0.6))
                else:
                    risk_score = max(75, min(95, risk_score * 0.9))
            except:
                # Model hatasƒ± durumunda kategoriye g√∂re risk ver
                if category == 'normal':
                    risk_score = np.random.uniform(15, 35)
                elif category == 'medium':
                    risk_score = np.random.uniform(45, 65)
                else:
                    risk_score = np.random.uniform(75, 95)
        else:
            # Model yoksa kategoriye g√∂re risk ver
            if category == 'normal':
                risk_score = np.random.uniform(15, 35)
            elif category == 'medium':
                risk_score = np.random.uniform(45, 65)
            else:
                risk_score = np.random.uniform(75, 95)
        
        # Risk seviyesi
        if risk_score < 40:
            risk_level = 'low'
        elif risk_score < 70:
            risk_level = 'medium'
        else:
            risk_level = 'high'
        
        sensor_data.update({
            'is_anomaly': risk_score >= 80,
            'anomaly_score': round(anomaly_score if model else -0.3, 4),
            'risk_score': round(risk_score, 2),
            'risk_level': risk_level,
            'risk_color': 'green' if risk_level == 'low' else ('yellow' if risk_level == 'medium' else 'red'),
            'anomali': 1 if risk_score >= 80 else 0
        })
        
        data.append(sensor_data)
    
    return pd.DataFrame(data)


def main():
    """Ana fonksiyon"""
    print("=" * 60)
    print("üîÑ Yeni Veri √úretimi Ba≈ülƒ±yor")
    print("=" * 60)
    
    # Klas√∂r kontrol√º
    os.makedirs('data', exist_ok=True)
    
    # Trafolarƒ± kategorilere daƒüƒ±t
    np.random.seed(42)
    categories = []
    for i in range(NUM_TRANSFORMERS):
        rand = np.random.random()
        if rand < 0.70:  # %70 normal
            categories.append('normal')
        elif rand < 0.90:  # %20 orta risk
            categories.append('medium')
        else:  # %10 y√ºksek risk
            categories.append('high')
    
    all_data = []
    
    print(f"\nüìä {NUM_TRANSFORMERS} trafo i√ßin veri √ºretiliyor...")
    print(f"   ‚Ä¢ Normal: {categories.count('normal')} trafo")
    print(f"   ‚Ä¢ Orta Risk: {categories.count('medium')} trafo")
    print(f"   ‚Ä¢ Y√ºksek Risk: {categories.count('high')} trafo")
    print()
    
    for i, category in enumerate(categories, 1):
        print(f"  ‚ö° Trafo {i}/{NUM_TRANSFORMERS} ({category})...", end='\r')
        df = generate_realistic_data(i, category, num_records=100)
        all_data.append(df)
    
    print(f"\n‚úÖ Veri √ºretimi tamamlandƒ±!")
    
    # T√ºm verileri birle≈ütir
    combined_df = pd.concat(all_data, ignore_index=True)
    combined_df = combined_df.sort_values(['timestamp', 'transformer_id']).reset_index(drop=True)
    
    # CSV'ye kaydet
    output_file = DATA_GENERATION['output_file']
    combined_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"\nüíæ Veri kaydedildi: {output_file}")
    print(f"üìà Toplam kayƒ±t: {len(combined_df):,}")
    print(f"üìä Risk Daƒüƒ±lƒ±mƒ±:")
    print(f"   ‚Ä¢ D√º≈ü√ºk Risk: {(combined_df['risk_score'] < 40).sum():,} kayƒ±t")
    print(f"   ‚Ä¢ Orta Risk: {((combined_df['risk_score'] >= 40) & (combined_df['risk_score'] < 70)).sum():,} kayƒ±t")
    print(f"   ‚Ä¢ Y√ºksek Risk: {(combined_df['risk_score'] >= 70).sum():,} kayƒ±t")
    
    return combined_df


if __name__ == "__main__":
    try:
        df = main()
        print("\n‚úÖ Veri √ºretimi ba≈üarƒ±yla tamamlandƒ±!")
    except Exception as e:
        print(f"\n‚ùå Hata olu≈ütu: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

