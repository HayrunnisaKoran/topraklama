"""
Dinamik Chat Sistemi - LLM Entegrasyonu
Model eÄŸitimi ve dinamik analiz iÃ§in
"""

from flask import Flask, jsonify, request
from flask_cors import CORS
import pandas as pd
import os
import json
from datetime import datetime, timedelta
import requests
from typing import Dict, List, Optional

# Mevcut modÃ¼lleri import et
from model_egit import load_model, predict_anomaly, calculate_risk_score
from config import (
    NUM_TRANSFORMERS,
    TRANSFORMER_LOCATIONS,
    SENSOR_RANGES,
    RISK_SCORING
)
from simulasyon import TransformerSimulator, AnomalyDetectionSystem

app = Flask(__name__)
CORS(app)

# Global deÄŸiÅŸkenler
detection_system = None
transformers = []
api_base_url = 'http://localhost:5000/api'
model = None
scaler = None

# LLM iÃ§in (Ollama veya OpenAI)
try:
    import ollama
    USE_OLLAMA = True
    print("[OK] Ollama bulundu - Yerel LLM kullanilacak")
except ImportError:
    USE_OLLAMA = False
    try:
        from openai import OpenAI
        client = OpenAI()
        USE_OPENAI = True
        print("[OK] OpenAI bulundu")
    except:
        USE_OPENAI = False
        print("[!] LLM bulunamadi - Basit analiz kullanilacak")


class ChatDataAccess:
    """Chat iÃ§in veri eriÅŸim katmanÄ± - Dinamik veri Ã§ekme"""
    
    def __init__(self):
        self.api_base = api_base_url
        self.sensor_data_path = 'data/sensor_data.csv'
        self.realtime_data_path = 'data/realtime_data.csv'
        self.sensor_df = None
        self.realtime_df = None
        
    def load_historical_data(self):
        """Tarihsel verileri yÃ¼kle"""
        try:
            if os.path.exists(self.sensor_data_path):
                print(f"Tarihsel veri yukleniyor: {self.sensor_data_path}")
                self.sensor_df = pd.read_csv(self.sensor_data_path)
                self.sensor_df['timestamp'] = pd.to_datetime(self.sensor_df['timestamp'])
                print(f"[OK] {len(self.sensor_df):,} kayit yuklendi")
            if os.path.exists(self.realtime_data_path):
                self.realtime_df = pd.read_csv(self.realtime_data_path)
                if 'timestamp' in self.realtime_df.columns:
                    self.realtime_df['timestamp'] = pd.to_datetime(self.realtime_df['timestamp'])
        except Exception as e:
            print(f"Veri yukleme hatasi: {e}")
    
    def get_transformer_current(self, transformer_id):
        """GÃ¼ncel trafo verisini API'den al - DINAMIK"""
        try:
            response = requests.get(f"{self.api_base}/transformers/{transformer_id}", timeout=5)
            if response.status_code == 200:
                return response.json().get('transformer')
        except Exception as e:
            print(f"API hatasi: {e}")
        return None
    
    def get_all_transformers(self):
        """TÃ¼m trafolarÄ± API'den al - DINAMIK"""
        try:
            response = requests.get(f"{self.api_base}/transformers", timeout=5)
            if response.status_code == 200:
                return response.json().get('transformers', [])
        except:
            pass
        return []
    
    def get_dashboard_stats(self):
        """Dashboard istatistiklerini al - DINAMIK"""
        try:
            response = requests.get(f"{self.api_base}/dashboard/stats", timeout=5)
            if response.status_code == 200:
                return response.json().get('stats')
        except:
            pass
        return None
    
    def get_transformer_history(self, transformer_id, days=30):
        """Trafo geÃ§miÅŸ verilerini al"""
        try:
            response = requests.get(f"{self.api_base}/transformers/{transformer_id}/history", timeout=5)
            if response.status_code == 200:
                return response.json().get('history', [])
        except:
            pass
        
        # CSV'den geÃ§miÅŸ veri
        if self.sensor_df is not None:
            df = self.sensor_df[self.sensor_df['transformer_id'] == transformer_id].copy()
            df = df.sort_values('timestamp')
            cutoff_date = datetime.now() - timedelta(days=days)
            df = df[df['timestamp'] >= cutoff_date]
            return df.to_dict('records')
        
        return []
    
    def analyze_trends(self, transformer_id, days=7):
        """Trend analizi yap - DINAMIK"""
        history = self.get_transformer_history(transformer_id, days=days)
        if len(history) < 2:
            return None
        
        # Son ve Ã¶nceki deÄŸerleri al
        current = history[-1].get('risk_score', 0) if isinstance(history[-1], dict) else 0
        previous = history[0].get('risk_score', 0) if isinstance(history[0], dict) else 0
        
        change = current - previous
        trend = 'artÄ±ÅŸ' if change > 0 else 'azalÄ±ÅŸ' if change < 0 else 'stabil'
        
        return {
            'trend': trend,
            'change': abs(change),
            'current': current,
            'previous': previous,
            'days': days
        }
    
    def find_similar_cases(self, transformer_data):
        """Benzer durumlarÄ± bul - DINAMIK ANALIZ"""
        if self.sensor_df is None:
            return []
        
        sensor_data = transformer_data.get('sensor_data', {})
        risk_score = transformer_data.get('risk_score', 0)
        
        # Benzer risk skorlarÄ±na sahip trafolarÄ± bul
        similar = []
        for trafo_id in range(1, NUM_TRANSFORMERS + 1):
            if trafo_id == transformer_data.get('id'):
                continue
            
            df = self.sensor_df[self.sensor_df['transformer_id'] == trafo_id]
            if len(df) == 0:
                continue
            
            # Son kayÄ±tlarÄ± al
            recent = df.tail(100)
            avg_risk = recent['anomali'].mean() * 100  # YaklaÅŸÄ±k risk
            
            if abs(avg_risk - risk_score) < 10:  # Â±10 puan iÃ§inde
                similar.append({
                    'transformer_id': trafo_id,
                    'similarity': 100 - abs(avg_risk - risk_score),
                    'avg_anomaly_rate': avg_risk
                })
        
        return sorted(similar, key=lambda x: x['similarity'], reverse=True)[:5]


class DynamicAnalyzer:
    """Dinamik analiz ve yorum yapar - Model kullanarak"""
    
    def __init__(self):
        self.sensor_ranges = SENSOR_RANGES
        self.risk_scoring = RISK_SCORING
        self.model = model
        self.scaler = scaler
    
    def analyze_transformer_detailed(self, transformer_data, history=None, trends=None):
        """DetaylÄ± trafo analizi - DINAMIK"""
        if not transformer_data:
            return None
        
        sensor_data = transformer_data.get('sensor_data', {})
        risk_score = transformer_data.get('risk_score', 0)
        risk_level = transformer_data.get('risk_level', 'unknown')
        is_anomaly = transformer_data.get('is_anomaly', False)
        
        analysis = {
            'status': 'normal',
            'critical_issues': [],
            'warnings': [],
            'root_causes': [],
            'solutions': [],
            'preventive_actions': [],
            'timeline': 'normal'
        }
        
        # Model ile anomali analizi
        if self.model and self.scaler:
            try:
                is_predicted_anomaly, anomaly_score = predict_anomaly(
                    self.model, self.scaler, sensor_data
                )
                if is_predicted_anomaly:
                    analysis['status'] = 'anomaly_detected'
                    analysis['anomaly_confidence'] = abs(anomaly_score)
            except:
                pass
        
        # DetaylÄ± sensÃ¶r analizi
        resistance = sensor_data.get('toprak_direnci', 0)
        leakage = sensor_data.get('kacak_akim', 0)
        corrosion = sensor_data.get('korozyon_seviyesi', 0)
        potential = sensor_data.get('toprak_potansiyel', 0)
        moisture = sensor_data.get('toprak_nemi', 0)
        temperature = sensor_data.get('toprak_sicakligi', 0)
        
        # Toprak Direnci Analizi
        normal_resistance = self.sensor_ranges['toprak_direnci']
        if resistance > 15:
            analysis['critical_issues'].append({
                'parameter': 'toprak_direnci',
                'value': resistance,
                'normal_range': f"{normal_resistance['min']}-{normal_resistance['max']} {normal_resistance['unit']}",
                'severity': 'critical',
                'description': f"Toprak direnci kritik seviyede ({resistance} Ohm). Bu, topraklama sisteminin etkinliÄŸini ciddi ÅŸekilde azaltÄ±r."
            })
            analysis['root_causes'].append("Korozyon, gevÅŸek baÄŸlantÄ±lar veya toprak kuruluÄŸu")
            analysis['solutions'].append({
                'action': 'Acil topraklama elektrodu kontrolÃ¼',
                'steps': [
                    'Topraklama elektrodu gÃ¶rsel kontrol',
                    'DirenÃ§ Ã¶lÃ§Ã¼mÃ¼ yapÄ±lmalÄ±',
                    'Gerekirse yeni elektrot takÄ±lmalÄ±',
                    'Toprak nemlendirme (kuru toprak durumunda)'
                ],
                'priority': 'high',
                'estimated_time': '2-4 saat'
            })
        elif resistance > 10:
            analysis['warnings'].append({
                'parameter': 'toprak_direnci',
                'value': resistance,
                'description': f"Toprak direnci yÃ¼ksek ({resistance} Ohm). Ã–nleyici bakÄ±m gerekli."
            })
            analysis['preventive_actions'].append({
                'action': 'Ã–nleyici bakÄ±m',
                'description': 'Korozyon kontrolÃ¼ ve toprak nemlendirme yapÄ±lmalÄ±',
                'priority': 'medium'
            })
        
        # KaÃ§ak AkÄ±m Analizi
        normal_leakage = self.sensor_ranges['kacak_akim']
        if leakage > 30:
            analysis['critical_issues'].append({
                'parameter': 'kacak_akim',
                'value': leakage,
                'normal_range': f"{normal_leakage['min']}-{normal_leakage['max']} {normal_leakage['unit']}",
                'severity': 'critical',
                'description': f"KaÃ§ak akÄ±m kritik seviyede ({leakage} mA). Elektrik gÃ¼venliÄŸi riski var."
            })
            analysis['root_causes'].append("Ä°zolasyon hatasÄ±, nem veya hasarlÄ± kablolar")
            analysis['solutions'].append({
                'action': 'Acil izolasyon kontrolÃ¼ ve trafo izolasyonu',
                'steps': [
                    'Trafo izole edilmeli (otomatik sistem devreye girmeli)',
                    'Ä°zolasyon testi yapÄ±lmalÄ±',
                    'HasarlÄ± kablolar deÄŸiÅŸtirilmeli',
                    'Nem kontrolÃ¼ yapÄ±lmalÄ±'
                ],
                'priority': 'critical',
                'estimated_time': '1-2 saat'
            })
        elif leakage > 20:
            analysis['warnings'].append({
                'parameter': 'kacak_akim',
                'value': leakage,
                'description': f"KaÃ§ak akÄ±m artÄ±yor ({leakage} mA). Ä°zolasyon kontrolÃ¼ gerekli."
            })
            analysis['preventive_actions'].append({
                'action': 'Ä°zolasyon testi',
                'description': 'Ã–nleyici izolasyon kontrolÃ¼ yapÄ±lmalÄ±',
                'priority': 'high'
            })
        
        # Korozyon Analizi
        if corrosion > 60:
            analysis['critical_issues'].append({
                'parameter': 'korozyon_seviyesi',
                'value': corrosion,
                'severity': 'critical',
                'description': f"Korozyon kritik seviyede ({corrosion}). Topraklama elektrodu deÄŸiÅŸimi gerekli."
            })
            analysis['root_causes'].append("Nem, tuzlu ortam veya kimyasal etkiler")
            analysis['solutions'].append({
                'action': 'Topraklama elektrodu deÄŸiÅŸimi',
                'steps': [
                    'Eski elektrot Ã§Ä±karÄ±lmalÄ±',
                    'Yeni korumalÄ± elektrot takÄ±lmalÄ±',
                    'Korozyon Ã¶nleyici kaplama uygulanmalÄ±',
                    'DÃ¼zenli kontrol planÄ± oluÅŸturulmalÄ±'
                ],
                'priority': 'high',
                'estimated_time': '4-6 saat'
            })
        elif corrosion > 40:
            analysis['warnings'].append({
                'parameter': 'korozyon_seviyesi',
                'value': corrosion,
                'description': f"Korozyon seviyesi yÃ¼ksek ({corrosion}). Ã–nleyici bakÄ±m planlanmalÄ±."
            })
            analysis['preventive_actions'].append({
                'action': 'Korozyon Ã¶nleyici bakÄ±m',
                'description': 'Koruyucu kaplama ve dÃ¼zenli temizlik yapÄ±lmalÄ±',
                'priority': 'medium'
            })
        
        # Trend analizi
        if trends:
            if trends['trend'] == 'artÄ±ÅŸ' and trends['change'] > 15:
                analysis['warnings'].append({
                    'parameter': 'risk_trend',
                    'description': f"Risk skoru son {trends['days']} gÃ¼nde {trends['change']:.1f} puan arttÄ±. HÄ±zlanan bozulma iÅŸareti."
                })
                analysis['preventive_actions'].append({
                    'action': 'Acil Ã¶nleyici bakÄ±m',
                    'description': 'Trend analizi kritik bozulma gÃ¶steriyor. Hemen mÃ¼dahale edilmeli',
                    'priority': 'high'
                })
        
        # Risk seviyesi deÄŸerlendirmesi
        if risk_level == 'high':
            analysis['status'] = 'critical'
            analysis['timeline'] = 'immediate_action_required'
        elif risk_level == 'medium':
            analysis['status'] = 'warning'
            analysis['timeline'] = 'preventive_maintenance_recommended'
        
        return analysis


class LLMResponseGenerator:
    """LLM ile dinamik yanÄ±t Ã¼retir"""
    
    def __init__(self):
        self.use_ollama = USE_OLLAMA
        self.use_openai = USE_OPENAI if not USE_OLLAMA else False
    
    def generate_response(self, question: str, context: Dict, analysis: Optional[Dict], recommendations: List) -> str:
        """Dinamik yanÄ±t Ã¼ret - LLM kullanarak"""
        
        # Context'i prompt'a dÃ¶nÃ¼ÅŸtÃ¼r
        prompt = self._build_prompt(question, context, analysis, recommendations)
        
        # LLM ile yanÄ±t Ã¼ret
        if self.use_ollama:
            return self._generate_with_ollama(prompt)
        elif self.use_openai:
            return self._generate_with_openai(prompt)
        else:
            return self._generate_fallback(question, context, analysis, recommendations)
    
    def _build_prompt(self, question: str, context: Dict, analysis: Optional[Dict], recommendations: List) -> str:
        """Prompt oluÅŸtur - Dinamik context ile"""
        
        prompt = f"""Sen bir topraklama izleme sistemi uzmanÄ±sÄ±n. KullanÄ±cÄ±ya teknik analiz ve Ã¶neriler sunuyorsun.

SORU: {question}

SÄ°STEM DURUMU:
"""
        
        if 'system_stats' in context and context['system_stats']:
            stats = context['system_stats']
            prompt += f"- Toplam trafo: {stats.get('total_transformers', 0)}\n"
            prompt += f"- Anomali sayÄ±sÄ±: {stats.get('anomaly_count', 0)}\n"
            prompt += f"- Ä°zole trafo: {stats.get('isolated_count', 0)}\n"
            prompt += f"- Ortalama risk: {stats.get('average_risk', 0):.1f}\n"
        
        if 'transformer' in context and context['transformer']:
            tf = context['transformer']
            prompt += f"""
TRAFO BÄ°LGÄ°LERÄ°:
- Ä°sim: {tf.get('name', 'Bilinmiyor')}
- BÃ¶lge: {tf.get('region', 'Bilinmiyor')}
- Risk Skoru: {tf.get('risk_score', 0):.1f} ({tf.get('risk_level', 'unknown')})
- Anomali: {'Evet' if tf.get('is_anomaly') else 'HayÄ±r'}
- Durum: {'Ä°zole' if not tf.get('isolation_status') else 'Aktif'}

SENSÃ–R VERÄ°LERÄ°:
- Toprak Direnci: {tf.get('sensor_data', {}).get('toprak_direnci', 0)} Ohm (Normal: 2-5 Ohm)
- KaÃ§ak AkÄ±m: {tf.get('sensor_data', {}).get('kacak_akim', 0)} mA (Normal: 0-10 mA)
- Toprak Potansiyeli: {tf.get('sensor_data', {}).get('toprak_potansiyel', 0)} V (Normal: -5-5 V)
- Toprak Nemi: {tf.get('sensor_data', {}).get('toprak_nemi', 0)} % (Normal: 20-60%)
- Toprak SÄ±caklÄ±ÄŸÄ±: {tf.get('sensor_data', {}).get('toprak_sicakligi', 0)} Â°C (Normal: 5-35Â°C)
- Korozyon Seviyesi: {tf.get('sensor_data', {}).get('korozyon_seviyesi', 0)} (Normal: 0-30)
"""
        
        if analysis:
            prompt += f"""
DETAYLI ANALÄ°Z:
"""
            if analysis.get('critical_issues'):
                prompt += "KRÄ°TÄ°K SORUNLAR:\n"
                for issue in analysis['critical_issues']:
                    prompt += f"- {issue.get('description', '')}\n"
            
            if analysis.get('warnings'):
                prompt += "UYARILAR:\n"
                for warning in analysis['warnings']:
                    if isinstance(warning, dict):
                        prompt += f"- {warning.get('description', '')}\n"
                    else:
                        prompt += f"- {warning}\n"
            
            if analysis.get('root_causes'):
                prompt += f"MUHTEMEL NEDENLER: {', '.join(analysis['root_causes'])}\n"
            
            if analysis.get('solutions'):
                prompt += "Ã‡Ã–ZÃœM Ã–NERÄ°LERÄ°:\n"
                for solution in analysis['solutions']:
                    prompt += f"- {solution.get('action', '')} (Ã–ncelik: {solution.get('priority', 'medium')}, SÃ¼re: {solution.get('estimated_time', 'bilinmiyor')})\n"
                    if solution.get('steps'):
                        for step in solution['steps']:
                            prompt += f"  * {step}\n"
        
        if recommendations:
            prompt += f"\nÃ–NERÄ°LER:\n"
            for rec in recommendations[:5]:
                prompt += f"- {rec}\n"
        
        prompt += """
GÃ–REVÄ°N:
1. KullanÄ±cÄ±nÄ±n sorusunu anla ve dinamik bir yanÄ±t ver
2. Teknik detaylarÄ± aÃ§Ä±k ve anlaÅŸÄ±lÄ±r ÅŸekilde aÃ§Ä±kla
3. SorunlarÄ± Ã¶nceden tespit et ve Ã¶neriler sun
4. HatalarÄ±n nasÄ±l Ã§Ã¶zÃ¼leceÄŸini adÄ±m adÄ±m aÃ§Ä±kla
5. Ã–nleyici bakÄ±m Ã¶nerileri ver
6. KodlanmÄ±ÅŸ mesajlar deÄŸil, gerÃ§ek zamanlÄ± analiz yap

YANIT (TÃ¼rkÃ§e, teknik ama anlaÅŸÄ±lÄ±r):
"""
        
        return prompt
    
    def _generate_with_ollama(self, prompt: str) -> str:
        """Ollama ile yanÄ±t Ã¼ret"""
        try:
            response = ollama.chat(
                model='llama3',  # veya llama3.2, mistral, vb.
                messages=[
                    {
                        'role': 'system',
                        'content': 'Sen bir topraklama izleme sistemi uzmanÄ±sÄ±n. Teknik analiz ve Ã¶neriler sunuyorsun.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ]
            )
            return response['message']['content']
        except Exception as e:
            print(f"Ollama hatasi: {e}")
            return self._generate_fallback_simple(prompt)
    
    def _generate_with_openai(self, prompt: str) -> str:
        """OpenAI ile yanÄ±t Ã¼ret"""
        try:
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": "Sen bir topraklama izleme sistemi uzmanÄ±sÄ±n. Teknik analiz ve Ã¶neriler sunuyorsun."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"OpenAI hatasi: {e}")
            return self._generate_fallback_simple(prompt)
    
    def _generate_fallback(self, question: str, context: Dict, analysis: Optional[Dict], recommendations: List) -> str:
        """LLM yoksa fallback yanÄ±t"""
        response = ""
        
        if 'transformer' in context and context['transformer']:
            tf = context['transformer']
            response = f"{tf.get('name', 'Trafo')} analizi:\n\n"
            
            if analysis:
                if analysis.get('critical_issues'):
                    response += "ðŸ”´ KRÄ°TÄ°K SORUNLAR:\n"
                    for issue in analysis['critical_issues']:
                        response += f"â€¢ {issue.get('description', '')}\n"
                    response += "\n"
                
                if analysis.get('solutions'):
                    response += "ðŸ’¡ Ã‡Ã–ZÃœM Ã–NERÄ°LERÄ°:\n"
                    for solution in analysis['solutions']:
                        response += f"â€¢ {solution.get('action', '')}\n"
                        if solution.get('steps'):
                            for step in solution['steps']:
                                response += f"  - {step}\n"
                    response += "\n"
        
        if recommendations:
            response += "ðŸ“‹ Ã–NERÄ°LER:\n"
            for rec in recommendations[:3]:
                response += f"â€¢ {rec}\n"
        
        return response if response else "Sistem analizi yapÄ±lÄ±yor..."
    
    def _generate_fallback_simple(self, prompt: str) -> str:
        """Basit fallback"""
        return "LLM modeli ÅŸu anda kullanÄ±lamÄ±yor. LÃ¼tfen Ollama veya OpenAI API anahtarÄ± yapÄ±landÄ±rÄ±n."


# Global instances
data_access = ChatDataAccess()
analyzer = DynamicAnalyzer()
llm_generator = LLMResponseGenerator()

# Verileri yÃ¼kle
data_access.load_historical_data()

# Model yÃ¼kle
try:
    model, scaler = load_model()
    analyzer.model = model
    analyzer.scaler = scaler
    print("[OK] Anomali tespit modeli yuklendi")
except Exception as e:
    print(f"[!] Model yuklenemedi: {e}")


@app.route('/api/chat', methods=['POST'])
def chat():
    """Dinamik chat endpoint - LLM ile"""
    try:
        data = request.get_json()
        question = data.get('question', '')
        transformer_id = data.get('transformer_id', None)
        
        if not question:
            return jsonify({
                'success': False,
                'error': 'Soru gerekli'
            }), 400
        
        # Context oluÅŸtur - DINAMIK VERI
        context = {
            'current_time': datetime.now().isoformat(),
            'question': question,
            'system_stats': data_access.get_dashboard_stats(),
        }
        
        if transformer_id:
            context['transformer'] = data_access.get_transformer_current(transformer_id)
            context['history'] = data_access.get_transformer_history(transformer_id, days=30)
            context['trends'] = data_access.analyze_trends(transformer_id, days=7)
            if context['transformer']:
                context['similar_cases'] = data_access.find_similar_cases(context['transformer'])
        else:
            context['all_transformers'] = data_access.get_all_transformers()
        
        # DetaylÄ± analiz - DINAMIK
        analysis = None
        if transformer_id and 'transformer' in context and context['transformer']:
            analysis = analyzer.analyze_transformer_detailed(
                context['transformer'],
                context.get('history'),
                context.get('trends')
            )
        
        # Ã–neriler
        recommendations = []
        if analysis:
            if analysis.get('solutions'):
                recommendations.extend([s.get('action', '') for s in analysis['solutions']])
            if analysis.get('preventive_actions'):
                recommendations.extend([a.get('action', '') for a in analysis['preventive_actions']])
        
        # LLM ile dinamik yanÄ±t Ã¼ret
        response = llm_generator.generate_response(question, context, analysis, recommendations)
        
        return jsonify({
            'success': True,
            'response': response,
            'analysis': analysis,
            'recommendations': recommendations,
            'context': {
                'transformer_id': transformer_id,
                'has_analysis': analysis is not None,
                'has_llm': llm_generator.use_ollama or llm_generator.use_openai
            }
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/chat/health', methods=['GET'])
def chat_health():
    """Chat sistemi saÄŸlÄ±k kontrolÃ¼"""
    return jsonify({
        'status': 'ok',
        'llm_available': llm_generator.use_ollama or llm_generator.use_openai,
        'model_loaded': model is not None,
        'data_loaded': data_access.sensor_df is not None,
        'timestamp': datetime.now().isoformat()
    })


if __name__ == '__main__':
    print("=" * 60)
    print("Dinamik Chat Backend API Baslatiliyor...")
    print("=" * 60)
    print(f"LLM Durumu: {'Ollama' if USE_OLLAMA else 'OpenAI' if USE_OPENAI else 'Yok (Fallback)'}")
    print(f"Model Durumu: {'Yuklu' if model else 'Yuklenemedi'}")
    print(f"Veri Durumu: {'Yuklu' if data_access.sensor_df is not None else 'Yuklenemedi'}")
    print("=" * 60)
    print("Endpoint: POST /api/chat")
    print("Health: GET /api/chat/health")
    print("=" * 60)
    
    app.run(debug=True, host='127.0.0.1', port=5001)

